\section{Librerie utilizzate}
I \textit{package} usati per realizzare il progetto sono:
\begin{itemize}
	\item \textit{numpy, versione 1.17.4}, è una libreria che aggiunge supporto a grandi matrici e \textit{array} multidimensionali insieme a una vasta collezione di funzioni matematiche di alto livello per poter operare efficientemente su queste strutture dati;
	\item \textit{jams, versione 0.3.4}, è una libreria che legge file \textit{JSON} inerenti al mondo della musica;
	\item \textit{librosa, versione 0.8.0}, è una libreria per la musica e l'analisi audio. Fornisce gli elementi necessari per recuperare informazioni musicali;
	\item \textit{scipy, versione 1.4.1}, è una libreria di algoritmi e strumenti matematici che contiene moduli per l'ottimizzazione, per l'algebra lineare, elaborazione di segnali ed immagini e altro;
	\item \textit{matplotlib, versione 3.1.2}, è una libreria per la creazione di grafici;
	\item \textit{tensorflow, versione 2.1.0}, è una libreria utilizzata per il \textit{machine learning} che fornisce moduli sperimentati e ottimizzati, utili nella realizzazione di algoritmi per diversi tipi di compiti percettivi e di comprensione del linguaggio.
	\item \textit{keras, versione 2.3.1}, consente di implementazione algoritmi basati su reti neurali. Permette di sviluppare e prototipare in maniera semplice e veloce modelli nell’ambito del \textit{machine learning} e del \textit{deep learning}. Supporta come \textit{back-end} \textit{Tensorflow} ed è integrata in esso dalla versione 2.
\end{itemize}

\section{Set dati GuitarSet}
Fortunatamente, su Internet abbiamo trovato un \textit{dataset} di file audio di chitarra già pronto su cui lavorare. Il \textit{GuitarSet}, chiamato così dal suo creatore, è costituito dai file audio e dai suoi \textit{tab}.\\
\newline
Questo \textit{dataset} contiene trecentosessanta estratti di canzoni della durata di circa trenta secondi l'uno. Quest'ultime sono suonate da sei persone diverse che leggono gli stessi fogli musicali. I fogli musicali sono generati da una combinazione di:
\begin{itemize}
	\item \textbf{5 stili}: rock, cantautore, bossa nova, jazz e funk;
	\item \textbf{3 progressioni}: dodici bar blues, autumn leaves e pachelbel canon;
	\item \textbf{2 Tempi}: lento e veloce.
\end{itemize}
Gli estratti sono registrati sia con il \textit{pickup esafonico} che con un microfono a condensatore \textit{Neumann U-87}.
Ci sono tre registrazioni audio per ogni estratto:
\begin{itemize}
	\item \textbf{hex}: file .\textit{wav} originali a sei canali dal \textit{pickup esafonico};
	\item \textbf{hex\_cln}: file .\textit{wav} con rimozione delle interferenze applicata;
	\item \textbf{mic}: registrazione monofonica dal microfono di riferimento
\end{itemize}
Noi abbiamo usato registrazioni di tipo \textbf{mic} perchè sono quelle che più si avvicinano al caso delle registrazioni tramite microfono dello \textit{smartphone}.\\
\newline
Ciascuno dei trecentosessanta estratti ha anche un file .\textit{jams} che memorizza sedici annotazioni da cui prenderemo le \textit{tab}:
\begin{itemize}
	\item Intonazione:
	\begin{itemize}
		\item 6 annotazioni \textit{pitch\_contour} (1 per stringa);
		\item 6 annotazioni \textit{midi\_note} (1 per stringa);
	\end{itemize}
	\item Beat e tempo:
	\begin{itemize}
		\item 1 annotazione \textit{beat\_position};
		\item 1 annotazione del tempo;
	\end{itemize}
	\item Accordi:
	\begin{itemize}
		\item 2 annotazioni di accordi (istruite ed eseguite).
	\end{itemize}
\end{itemize}
Noi useremo le annotazioni \textit{midi\_note}.
\subsection{Ricavare le tab dai file .jams}
Innanzitutto calcoliamo i \textit{frame} per ogni \textit{file} audio, così da poter ricavare un'immagine e la corrispondente \textit{tab} per ogni \textit{frame}. Per calcolare l'istante di tempo per ogni \textit{frame} utilizziamo la funzione \textit{get\_times()}
\vspace*{2ex}
\pythonexternal{./codes/times.py}
\vspace*{2ex}
Adesso che, per ogni \textit{file} audio, abbiamo una divisione in \textit{frame} di cui conosciamo gli istanti di tempo esatti, possiamo estarre dai file .\textit{jams} del \textit{dataset} le \textit{tab} corrispondenti.\\ Più precisamente, dai file .\textit{jams} prendiamo le note \textit{MIDI} e creiamo una matrice 6x19 dove il sei rappresenta il numero di corde mentre il diciannove rappresenta il numero di tasti.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.30]{./images/img12.jpg}
\end{figure}
Ogni tasto della matrice ha un valore \textit{MIDI} che varia da 40 a 82.
\vspace*{2ex}
\pythonexternal{./codes/matrixMidi.py}
\vspace*{2ex}
Ad ogni matrice sostituiamo i valori \textit{MIDI} con una matrice della stessa dimensione in cui ci sono solo uni o zeri a seconda dei valori \textit{MIDI} che il \textit{file} .\textit{jams} ci ha restituito. Ad esempio, se dal file .\textit{jams} abbiamo che in quel frame sono state suonate le note 40, 62 e 65 avremmo la seguente matrice:
\vspace*{2ex}
\pythonexternal{./codes/matrixUniZeri.py}
\vspace*{2ex}
Dato che una nota si può trovare su più corde, alla fine bisogna sceglierne soltanto una perchè il suono è lo stesso. Dunque, gli "1" in più devono essere cancellati. Inoltre, siccome queste matrici che chiameremo \textit{labels} le daremo in \textit{input} al modello è importante avere i dati categorici, quindi devono essere mappati come numeri interi per cui useremo la codifica \textit{one-hot}, cioè si può trovare un "1" solo in ogni riga. A questa matrice aggiungiamo altre due colonne che servono a capire se la corda è stata suonata (colonna 0) e se si, se è stata suonata a vuoto (colonna 1) oppure no.\\
\newline
Di conseguenza, la matrice finale di dimensione 6x21 è la seguente:
\vspace*{2ex}
\pythonexternal{./codes/matrixUniZeriFinale.py}
\vspace*{2ex}
Il codice che esegue quanto abbiamo appena descritto è il seguente:
\vspace*{2ex}
\pythonexternal{./codes/labels.py}
\subsection{Ricavare le immagini dai file audio}
Dopo aver trovato i \textit{label} per ogni \textit{frame}, dobbiamo trovare un modo per far imparare al modello che un frammento di audio sia associato al corrispondente \textit{label}.
Grazie a \textit{librosa} possiamo convertire i \textit{file} audio in immagini. Per far ciò usiamo la trasformata a Q costante che ci viene fornita da questa libreria e che ricava per ogni \textit{file} audio un'immagine.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.60]{./images/img7.png}
\end{figure}
\vspace*{2ex}
\pythonexternal{./codes/librosa.py}
\vspace*{2ex}
I dati (\textit{images} e \textit{labels}) di ogni \textit{file} audio sono stati compressi in archivi .\textit{npz} per organizzare meglio il \textit{dataset} da dare come \textit{input} al modello.
\subsection{Pre-elaborare i dati}
Carichiamo i \textit{file} .\textit{npz} e per ogni immagine aggiungiamo quattro zeri nell'\textit{array} in cui ci sono tutte le immagini sia all'inizio che alla fine. Questo perchè per ogni \textit{frame} salviamo nove righe alla volta che corrispondono a 0.2 secondi.\\
\newline
Viene aggiunto un padding perchè così l'ultimo valore, della finestra di 9, risulta essere congruo con gli altri. (matrice)
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.30]{./images/img12.jpg}
\end{figure}
Il codice che esegue quanto abbiamo appena descritto è il seguente:
\vspace*{2ex}
\pythonexternal{./codes/preElaborazionedati1.py}
\vspace*{2ex}
Una volta ottenuto l'\textit{array} di tutte le \textit{images} e i \textit{labels} dei \textit{file} audio, e assegnati rispettivamente le variabili X e Y, lo mescoliamo in modo da avere più imprevedibilità. Infine, suddividiamo questi dati nel seguente modo:
\begin{itemize}
	\item 10\% dei dati li usiamo per la \textit{validation}
	\item 10\% dei dati li usiamo per i \textit{test}
	\item 80\% dei dati li usiamo per il \textit{traning}
\end{itemize}
il \textit{traning set} lo usiamo per costruire il modello, il \textit{validation set} per validare i parametri dei layer della rete neurale mentre il \textit{test set} per determinare l'accuratezza.\\
\newline
Il codice è il seguente:
\vspace*{2ex}
\pythonexternal{./codes/preElaborazionedati2.py}
\vspace*{2ex}
\section{Modello della rete}
La difficoltà nell’apprendere i meccanismi di implementazione su \textit{Keras} sono ridotti al minimo grazie alla vasta documentazione presente, arricchita da numerosi esempi sulle più utilizzate configurazioni inerenti il \textit{machine learning}, come \textit{CNN} (Convolutional Neural Network).
Le operazioni di calcolo matriciali possono essere accelerate sia tramite \textit{CPU}, che \textit{GPU} (su hardware \textit{Nvidia} con supporto \textit{CUDA}).
Le caratteristiche e i vantaggi che ci hanno portato ad utilizzarlo nell’ambito del progetto sono:
\begin{itemize}
	\item \textbf{semplicità}: a differenza di altre \textit{API}, è possibile realizzare modelli complessi scrivendo meno righe di codice, mantenendo nel contempo chiarezza nello sviluppo. Tutto ciò consente allo sviluppatore di mantenere nel tempo il codice in maniera agevole.
	\item \textbf{modularità}: un modello in \textit{Keras} è inteso come una sequenza o un grafo di singoli, compatti e completamente configurabili moduli, che possono lavorare in sinergia tra loro con il minimo numero di restrizioni possibili. Ciò rende il codice estremamente flessibile.
	\item \textbf{estensibilità}: in base alle esigenze dello sviluppatore, è possibile aggiungere facilmente nuovi moduli (ad esempio classi e funzioni) ad un progetto preesistente.
\end{itemize}
\subsection{Uso di Keras}
Prima di dare in \textit{input} al modello il \textit{traning set} e il \textit{validation set}, dobbiamo fare delle modifiche alla dimensione del numpy \textit{array} delle immagini di nome X in quanto il modello si aspetta un \textit{input} di \textit{BATCH} x 192 x 9 x 1.
\begin{itemize}
	\item \textit{BATCH} sono la quantità di valori dell'intero \textit{traning set};
	\item 192 è l'altezza dell'immagine;
	\item 9 è la lunghezza dell'immagine;
	\item 1 ci indica che l'immagine è in bianco e nero.
\end{itemize}
La Y non ha bisogno di modifiche perchè le dimensioni sono già quelle corrette cioè ha dimensione \textit{BATCH} x 21 x 6.\\
\newline
Il codice che esegue quanto abbiamo appena descritto è il seguente:
\vspace*{2ex}
\pythonexternal{./codes/modelloFinale1.py}
\vspace*{2ex}
A questo punto definiamo il modello:
\begin{itemize}
	\item \textbf{Conv2D}: serve per mettere in evidenza le caratteristiche interessanti dell'immagine. parametri di \textit{input}: numero di filtri, grandezza filtri, input shape e funzione di attivazione.
	\item \textbf{MaxPooling2D}: riduce la dimensione dell'immagine, elimina le informazioni inutili mantenendo quelle più importanti. parametri di \textit{input}: matrice di input;
	\item \textbf{Dropout} elimina una percentuale di dati casuali. Ad esempio, elimina rumori di sottofondo e mantiene le informazioni più importanti. Parametri di \textit{input}: percentuale.
	\item \textbf{Flattern} appiattisce il tensore e rimuove tutte le dimensioni;
	\item \textbf{Dense}: decide il numero di numero di neuroni in uscita.
	\item \textbf{Reshape}: determina la dimensione di uscita. In questo caso è 6x21;
	\item \textbf{Activation} serve affinchè la somma di ogni elemento di uscita sia uno.
\end{itemize}
\begin{figure}[H]
	\centering
	\includegraphics[scale=1.4]{./images/model.png}
\end{figure}
Per compilare il modello abbiamo scelto come ottimizzatore l'algoritmo \textit{Adadelta} che utilizza un metodo di discesa del gradiente stocastico basato sul tasso di apprendimento adattivo per dimensione per affrontare l'inconveniente del continuo declino dei tassi di apprendimento durante la formazione e la necessità di un tasso di apprendimento globale selezionato manualmente.\\
Il codice è il seguente:\\
\newline
\vspace*{2ex}
\pythonexternal{./codes/modelloFinale3.py}
\vspace*{2ex}
Questo è il \textit{summary} del modello:
\vspace*{2ex}
\pythonexternal{./codes/modelloFinale5.py}
\vspace*{2ex}
In particolare, per il modello abbiamo usato delle funzioni personalizzate per la funzione di attivazione finale del modello (\textit{sofmax\_by\_string}), per la funzione obiettivo \textit{loss} (\textit{catcross\_by\_string}) e per le metriche (\textit{avg\_acc}) che devono essere valutate del modello durante l'addestramento e il modello.\\
\newline
Il codice che esegue quanto abbiamo appena descritto è il seguente:
\vspace*{2ex}
\pythonexternal{./codes/modelloFinale2.py}
\vspace*{2ex}
Per avviare l'addestramento del modello eseguiamo il comando \textit{model.fit()} dove indichiamo con \textit{batch\_size} il numero di campioni per ogni aggiornamento del gradiente e con \textit{epochs} il numero di iterazioni sul quale il modello deve effettuare il \textit{traning}.\\
\newline
Il codice che esegue quanto abbiamo appena descritto è il seguente:
\vspace*{2ex}
\pythonexternal{./codes/modelloFinale4.py}
\vspace*{2ex}
\subsection{Addestramento del modello}
Dopo diverse prove sperimentali, abbiamo deciso di eseguire il modello per cinquecento:
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{./images/storia.png}
\end{figure}
Questo modello raggiunge una precisione di circa 0,87 (o 87\%) e una perdita del 2\% sui dati di addestramento. Invece, sui dati di validazione la precisione supera lo 0,90 (90\%) e raggiunge una perdita del 1,6\% sui dati di validazione. I \textit{loss} sono la media delle perdite sui dati di \textit{batch} di addestramento.\\
\newline
Il grafico sottostante ci fa comprendere meglio i risultati:
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{./images/plot.png}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.35]{./images/plot2.png}
\end{figure}

\section{Valutazione del modello}
Abbiamo eseguito diversi \textit{test} per mettere alla prova il modello utilizzando il \textit{training test}. La matrice \textit{Answer} è la y corrispondente alla X data come \textit{input} alla \textit{predict}. Invece, la \textit{Prediction} corrisponde all'output della rete. Il valore più grande della riga corrisponde a dove secondo il modello ci debba essere l'"1".\\
\newline
Di seguito riportiamo un esempio:
\vspace*{2ex}
\pythonexternal{./codes/test.py}
\vspace*{2ex}
Abbiamo confrontato le prestazioni del modello sul \textit{dataset} di prova e i risultati sono stati quelli previsti. Infatti, l'accuratezza e la perdita dei dati di \textit{test} sono molto simili a quelli dei dati di validazione.
\vspace*{2ex}
\pythonexternal{./codes/valutazione.py}
\vspace*{2ex}

Il codice che esegue quanto abbiamo appena descritto è il seguente:
\vspace*{2ex}
\pythonexternal{./codes/accuratezza.py}
\vspace*{2ex}