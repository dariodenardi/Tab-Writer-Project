Train on 378048 samples, validate on 47256 samples
Epoch 1/250
2021-03-06 16:18:37.095418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2021-03-06 16:18:37.608238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2021-03-06 16:18:39.389676: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. This message will be only logged once.
378048/378048 [==============================] - 52s 137us/sample - loss: 12.3130 - avg_acc: 0.5606 - val_loss: 8.1167 - val_avg_acc: 0.7126
Epoch 2/250
378048/378048 [==============================] - 46s 123us/sample - loss: 8.7713 - avg_acc: 0.7066 - val_loss: 7.6353 - val_avg_acc: 0.7126
Epoch 3/250
378048/378048 [==============================] - 47s 123us/sample - loss: 8.3006 - avg_acc: 0.7082 - val_loss: 7.3022 - val_avg_acc: 0.7127
Epoch 4/250
378048/378048 [==============================] - 46s 122us/sample - loss: 7.9387 - avg_acc: 0.7084 - val_loss: 6.9833 - val_avg_acc: 0.7145
Epoch 5/250
378048/378048 [==============================] - 46s 122us/sample - loss: 7.6175 - avg_acc: 0.7091 - val_loss: 6.6547 - val_avg_acc: 0.7181
Epoch 6/250
378048/378048 [==============================] - 46s 122us/sample - loss: 7.3137 - avg_acc: 0.7110 - val_loss: 6.3492 - val_avg_acc: 0.7231
Epoch 7/250
378048/378048 [==============================] - 46s 122us/sample - loss: 7.0549 - avg_acc: 0.7138 - val_loss: 6.0678 - val_avg_acc: 0.7292
Epoch 8/250
378048/378048 [==============================] - 46s 122us/sample - loss: 6.8061 - avg_acc: 0.7177 - val_loss: 5.8038 - val_avg_acc: 0.7362
Epoch 9/250
378048/378048 [==============================] - 46s 122us/sample - loss: 6.5835 - avg_acc: 0.7224 - val_loss: 5.5596 - val_avg_acc: 0.7431
Epoch 10/250
378048/378048 [==============================] - 46s 123us/sample - loss: 6.3735 - avg_acc: 0.7271 - val_loss: 5.3381 - val_avg_acc: 0.7489
Epoch 11/250
378048/378048 [==============================] - 47s 123us/sample - loss: 6.1865 - avg_acc: 0.7316 - val_loss: 5.1397 - val_avg_acc: 0.7543
Epoch 12/250
378048/378048 [==============================] - 47s 125us/sample - loss: 6.0233 - avg_acc: 0.7357 - val_loss: 4.9642 - val_avg_acc: 0.7592
Epoch 13/250
378048/378048 [==============================] - 47s 125us/sample - loss: 5.8750 - avg_acc: 0.7393 - val_loss: 4.8097 - val_avg_acc: 0.7644
Epoch 14/250
378048/378048 [==============================] - 47s 124us/sample - loss: 5.7425 - avg_acc: 0.7427 - val_loss: 4.6826 - val_avg_acc: 0.7677
Epoch 15/250
378048/378048 [==============================] - 47s 125us/sample - loss: 5.6225 - avg_acc: 0.7460 - val_loss: 4.5630 - val_avg_acc: 0.7720
Epoch 16/250
378048/378048 [==============================] - 47s 124us/sample - loss: 5.5187 - avg_acc: 0.7487 - val_loss: 4.4603 - val_avg_acc: 0.7753
Epoch 17/250
378048/378048 [==============================] - 48s 127us/sample - loss: 5.4192 - avg_acc: 0.7514 - val_loss: 4.3697 - val_avg_acc: 0.7783
Epoch 18/250
378048/378048 [==============================] - 47s 125us/sample - loss: 5.3347 - avg_acc: 0.7535 - val_loss: 4.2901 - val_avg_acc: 0.7806
Epoch 19/250
378048/378048 [==============================] - 47s 124us/sample - loss: 5.2521 - avg_acc: 0.7556 - val_loss: 4.2161 - val_avg_acc: 0.7830
Epoch 20/250
378048/378048 [==============================] - 46s 122us/sample - loss: 5.1799 - avg_acc: 0.7578 - val_loss: 4.1449 - val_avg_acc: 0.7854
Epoch 21/250
378048/378048 [==============================] - 45s 119us/sample - loss: 5.1109 - avg_acc: 0.7596 - val_loss: 4.0840 - val_avg_acc: 0.7878
Epoch 22/250
378048/378048 [==============================] - 45s 119us/sample - loss: 5.0471 - avg_acc: 0.7613 - val_loss: 4.0267 - val_avg_acc: 0.7898
Epoch 23/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.9860 - avg_acc: 0.7630 - val_loss: 3.9698 - val_avg_acc: 0.7922
Epoch 24/250
378048/378048 [==============================] - 44s 117us/sample - loss: 4.9266 - avg_acc: 0.7647 - val_loss: 3.9172 - val_avg_acc: 0.7941
Epoch 25/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.8758 - avg_acc: 0.7663 - val_loss: 3.8693 - val_avg_acc: 0.7955
Epoch 26/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.8233 - avg_acc: 0.7678 - val_loss: 3.8223 - val_avg_acc: 0.7972
Epoch 27/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.7713 - avg_acc: 0.7694 - val_loss: 3.7767 - val_avg_acc: 0.7993
Epoch 28/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.7239 - avg_acc: 0.7706 - val_loss: 3.7342 - val_avg_acc: 0.8009
Epoch 29/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.6762 - avg_acc: 0.7719 - val_loss: 3.6921 - val_avg_acc: 0.8025
Epoch 30/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.6320 - avg_acc: 0.7736 - val_loss: 3.6518 - val_avg_acc: 0.8044
Epoch 31/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.5880 - avg_acc: 0.7746 - val_loss: 3.6168 - val_avg_acc: 0.8055
Epoch 32/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.5466 - avg_acc: 0.7758 - val_loss: 3.5816 - val_avg_acc: 0.8070
Epoch 33/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.5089 - avg_acc: 0.7769 - val_loss: 3.5447 - val_avg_acc: 0.8087
Epoch 34/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.4693 - avg_acc: 0.7781 - val_loss: 3.5117 - val_avg_acc: 0.8100
Epoch 35/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.4354 - avg_acc: 0.7792 - val_loss: 3.4808 - val_avg_acc: 0.8113
Epoch 36/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.4000 - avg_acc: 0.7803 - val_loss: 3.4498 - val_avg_acc: 0.8127
Epoch 37/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.3636 - avg_acc: 0.7813 - val_loss: 3.4208 - val_avg_acc: 0.8140
Epoch 38/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.3319 - avg_acc: 0.7825 - val_loss: 3.3907 - val_avg_acc: 0.8152
Epoch 39/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.2980 - avg_acc: 0.7833 - val_loss: 3.3638 - val_avg_acc: 0.8163
Epoch 40/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.2657 - avg_acc: 0.7844 - val_loss: 3.3381 - val_avg_acc: 0.8174
Epoch 41/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.2346 - avg_acc: 0.7854 - val_loss: 3.3107 - val_avg_acc: 0.8186
Epoch 42/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.2046 - avg_acc: 0.7863 - val_loss: 3.2849 - val_avg_acc: 0.8199
Epoch 43/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.1752 - avg_acc: 0.7874 - val_loss: 3.2600 - val_avg_acc: 0.8211
Epoch 44/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.1430 - avg_acc: 0.7883 - val_loss: 3.2346 - val_avg_acc: 0.8220
Epoch 45/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.1203 - avg_acc: 0.7891 - val_loss: 3.2155 - val_avg_acc: 0.8225
Epoch 46/250
378048/378048 [==============================] - 45s 119us/sample - loss: 4.0921 - avg_acc: 0.7900 - val_loss: 3.1916 - val_avg_acc: 0.8238
Epoch 47/250
378048/378048 [==============================] - 47s 123us/sample - loss: 4.0679 - avg_acc: 0.7909 - val_loss: 3.1683 - val_avg_acc: 0.8252
Epoch 48/250
378048/378048 [==============================] - 46s 122us/sample - loss: 4.0371 - avg_acc: 0.7920 - val_loss: 3.1490 - val_avg_acc: 0.8256
Epoch 49/250
378048/378048 [==============================] - 46s 121us/sample - loss: 4.0118 - avg_acc: 0.7926 - val_loss: 3.1267 - val_avg_acc: 0.8267
Epoch 50/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.9875 - avg_acc: 0.7935 - val_loss: 3.1051 - val_avg_acc: 0.8278
Epoch 51/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.9654 - avg_acc: 0.7940 - val_loss: 3.0843 - val_avg_acc: 0.8286
Epoch 52/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.9455 - avg_acc: 0.7950 - val_loss: 3.0665 - val_avg_acc: 0.8292
Epoch 53/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.9214 - avg_acc: 0.7957 - val_loss: 3.0465 - val_avg_acc: 0.8304
Epoch 54/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.8965 - avg_acc: 0.7965 - val_loss: 3.0288 - val_avg_acc: 0.8309
Epoch 55/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.8781 - avg_acc: 0.7973 - val_loss: 3.0069 - val_avg_acc: 0.8325
Epoch 56/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.8559 - avg_acc: 0.7979 - val_loss: 2.9914 - val_avg_acc: 0.8329
Epoch 57/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.8326 - avg_acc: 0.7989 - val_loss: 2.9721 - val_avg_acc: 0.8338
Epoch 58/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.8113 - avg_acc: 0.7996 - val_loss: 2.9577 - val_avg_acc: 0.8344
Epoch 59/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.7924 - avg_acc: 0.8004 - val_loss: 2.9401 - val_avg_acc: 0.8350
Epoch 60/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.7710 - avg_acc: 0.8007 - val_loss: 2.9237 - val_avg_acc: 0.8359
Epoch 61/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.7545 - avg_acc: 0.8014 - val_loss: 2.9074 - val_avg_acc: 0.8367
Epoch 62/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.7305 - avg_acc: 0.8025 - val_loss: 2.8904 - val_avg_acc: 0.8377
Epoch 63/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.7194 - avg_acc: 0.8031 - val_loss: 2.8769 - val_avg_acc: 0.8385
Epoch 64/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.6952 - avg_acc: 0.8037 - val_loss: 2.8629 - val_avg_acc: 0.8390
Epoch 65/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.6814 - avg_acc: 0.8041 - val_loss: 2.8480 - val_avg_acc: 0.8395
Epoch 66/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.6652 - avg_acc: 0.8049 - val_loss: 2.8352 - val_avg_acc: 0.8401
Epoch 67/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.6458 - avg_acc: 0.8056 - val_loss: 2.8204 - val_avg_acc: 0.8409
Epoch 68/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.6296 - avg_acc: 0.8060 - val_loss: 2.8066 - val_avg_acc: 0.8416
Epoch 69/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.6126 - avg_acc: 0.8070 - val_loss: 2.7917 - val_avg_acc: 0.8424
Epoch 70/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.5967 - avg_acc: 0.8073 - val_loss: 2.7791 - val_avg_acc: 0.8430
Epoch 71/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.5813 - avg_acc: 0.8081 - val_loss: 2.7649 - val_avg_acc: 0.8437
Epoch 72/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.5640 - avg_acc: 0.8087 - val_loss: 2.7531 - val_avg_acc: 0.8443
Epoch 73/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.5512 - avg_acc: 0.8088 - val_loss: 2.7416 - val_avg_acc: 0.8446
Epoch 74/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.5373 - avg_acc: 0.8096 - val_loss: 2.7276 - val_avg_acc: 0.8456
Epoch 75/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.5193 - avg_acc: 0.8105 - val_loss: 2.7195 - val_avg_acc: 0.8457
Epoch 76/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.5105 - avg_acc: 0.8107 - val_loss: 2.7062 - val_avg_acc: 0.8465
Epoch 77/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.4906 - avg_acc: 0.8116 - val_loss: 2.6959 - val_avg_acc: 0.8469
Epoch 78/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.4744 - avg_acc: 0.8123 - val_loss: 2.6824 - val_avg_acc: 0.8478
Epoch 79/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.4621 - avg_acc: 0.8130 - val_loss: 2.6709 - val_avg_acc: 0.8484
Epoch 80/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.4520 - avg_acc: 0.8129 - val_loss: 2.6620 - val_avg_acc: 0.8486
Epoch 81/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.4404 - avg_acc: 0.8135 - val_loss: 2.6504 - val_avg_acc: 0.8493
Epoch 82/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.4304 - avg_acc: 0.8139 - val_loss: 2.6421 - val_avg_acc: 0.8497
Epoch 83/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.4156 - avg_acc: 0.8145 - val_loss: 2.6316 - val_avg_acc: 0.8502
Epoch 84/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.4045 - avg_acc: 0.8148 - val_loss: 2.6212 - val_avg_acc: 0.8508
Epoch 85/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.3884 - avg_acc: 0.8159 - val_loss: 2.6125 - val_avg_acc: 0.8511
Epoch 86/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.3821 - avg_acc: 0.8161 - val_loss: 2.6045 - val_avg_acc: 0.8516
Epoch 87/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.3673 - avg_acc: 0.8164 - val_loss: 2.5930 - val_avg_acc: 0.8523
Epoch 88/250
378048/378048 [==============================] - 46s 123us/sample - loss: 3.3565 - avg_acc: 0.8168 - val_loss: 2.5833 - val_avg_acc: 0.8529
Epoch 89/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.3454 - avg_acc: 0.8177 - val_loss: 2.5747 - val_avg_acc: 0.8531
Epoch 90/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.3324 - avg_acc: 0.8178 - val_loss: 2.5652 - val_avg_acc: 0.8537
Epoch 91/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.3214 - avg_acc: 0.8186 - val_loss: 2.5568 - val_avg_acc: 0.8540
Epoch 92/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.3115 - avg_acc: 0.8188 - val_loss: 2.5479 - val_avg_acc: 0.8547
Epoch 93/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.3004 - avg_acc: 0.8195 - val_loss: 2.5397 - val_avg_acc: 0.8548
Epoch 94/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2901 - avg_acc: 0.8196 - val_loss: 2.5323 - val_avg_acc: 0.8552
Epoch 95/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2800 - avg_acc: 0.8202 - val_loss: 2.5251 - val_avg_acc: 0.8555
Epoch 96/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2695 - avg_acc: 0.8207 - val_loss: 2.5145 - val_avg_acc: 0.8562
Epoch 97/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2617 - avg_acc: 0.8211 - val_loss: 2.5075 - val_avg_acc: 0.8565
Epoch 98/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2528 - avg_acc: 0.8212 - val_loss: 2.5004 - val_avg_acc: 0.8569
Epoch 99/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2443 - avg_acc: 0.8215 - val_loss: 2.4917 - val_avg_acc: 0.8574
Epoch 100/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2335 - avg_acc: 0.8219 - val_loss: 2.4845 - val_avg_acc: 0.8577
Epoch 101/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2232 - avg_acc: 0.8225 - val_loss: 2.4799 - val_avg_acc: 0.8578
Epoch 102/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2153 - avg_acc: 0.8227 - val_loss: 2.4700 - val_avg_acc: 0.8586
Epoch 103/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.2050 - avg_acc: 0.8234 - val_loss: 2.4623 - val_avg_acc: 0.8589
Epoch 104/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.1969 - avg_acc: 0.8238 - val_loss: 2.4584 - val_avg_acc: 0.8590
Epoch 105/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.1890 - avg_acc: 0.8242 - val_loss: 2.4493 - val_avg_acc: 0.8595
Epoch 106/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.1762 - avg_acc: 0.8247 - val_loss: 2.4418 - val_avg_acc: 0.8598
Epoch 107/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.1722 - avg_acc: 0.8247 - val_loss: 2.4370 - val_avg_acc: 0.8601
Epoch 108/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.1608 - avg_acc: 0.8256 - val_loss: 2.4304 - val_avg_acc: 0.8605
Epoch 109/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.1528 - avg_acc: 0.8258 - val_loss: 2.4231 - val_avg_acc: 0.8609
Epoch 110/250
378048/378048 [==============================] - 45s 119us/sample - loss: 3.1468 - avg_acc: 0.8260 - val_loss: 2.4169 - val_avg_acc: 0.8611
Epoch 111/250
378048/378048 [==============================] - 48s 126us/sample - loss: 3.1363 - avg_acc: 0.8266 - val_loss: 2.4093 - val_avg_acc: 0.8615
Epoch 112/250
378048/378048 [==============================] - 47s 124us/sample - loss: 3.1330 - avg_acc: 0.8266 - val_loss: 2.4030 - val_avg_acc: 0.8621
Epoch 113/250
378048/378048 [==============================] - 47s 124us/sample - loss: 3.1250 - avg_acc: 0.8270 - val_loss: 2.3990 - val_avg_acc: 0.8619
Epoch 114/250
378048/378048 [==============================] - 47s 124us/sample - loss: 3.1134 - avg_acc: 0.8277 - val_loss: 2.3930 - val_avg_acc: 0.8624
Epoch 115/250
378048/378048 [==============================] - 47s 124us/sample - loss: 3.1092 - avg_acc: 0.8275 - val_loss: 2.3869 - val_avg_acc: 0.8626
Epoch 116/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.1019 - avg_acc: 0.8282 - val_loss: 2.3811 - val_avg_acc: 0.8629
Epoch 117/250
378048/378048 [==============================] - 47s 123us/sample - loss: 3.0940 - avg_acc: 0.8283 - val_loss: 2.3744 - val_avg_acc: 0.8634
Epoch 118/250
378048/378048 [==============================] - 60s 158us/sample - loss: 3.0855 - avg_acc: 0.8285 - val_loss: 2.3687 - val_avg_acc: 0.8637
Epoch 119/250
378048/378048 [==============================] - 75s 200us/sample - loss: 3.0810 - avg_acc: 0.8287 - val_loss: 2.3624 - val_avg_acc: 0.8641
Epoch 120/250
378048/378048 [==============================] - 60s 158us/sample - loss: 3.0736 - avg_acc: 0.8294 - val_loss: 2.3595 - val_avg_acc: 0.8640
Epoch 121/250
378048/378048 [==============================] - 45s 120us/sample - loss: 3.0660 - avg_acc: 0.8298 - val_loss: 2.3528 - val_avg_acc: 0.8645
Epoch 122/250
378048/378048 [==============================] - 47s 123us/sample - loss: 3.0586 - avg_acc: 0.8300 - val_loss: 2.3472 - val_avg_acc: 0.8648
Epoch 123/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.0503 - avg_acc: 0.8302 - val_loss: 2.3434 - val_avg_acc: 0.8648
Epoch 124/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.0456 - avg_acc: 0.8305 - val_loss: 2.3370 - val_avg_acc: 0.8653
Epoch 125/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.0383 - avg_acc: 0.8310 - val_loss: 2.3316 - val_avg_acc: 0.8656
Epoch 126/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.0326 - avg_acc: 0.8313 - val_loss: 2.3252 - val_avg_acc: 0.8660
Epoch 127/250
378048/378048 [==============================] - 45s 120us/sample - loss: 3.0236 - avg_acc: 0.8317 - val_loss: 2.3206 - val_avg_acc: 0.8662
Epoch 128/250
378048/378048 [==============================] - 46s 122us/sample - loss: 3.0201 - avg_acc: 0.8316 - val_loss: 2.3173 - val_avg_acc: 0.8664
Epoch 129/250
378048/378048 [==============================] - 47s 123us/sample - loss: 3.0153 - avg_acc: 0.8318 - val_loss: 2.3094 - val_avg_acc: 0.8671
Epoch 130/250
378048/378048 [==============================] - 45s 120us/sample - loss: 3.0052 - avg_acc: 0.8323 - val_loss: 2.3056 - val_avg_acc: 0.8672
Epoch 131/250
378048/378048 [==============================] - 45s 120us/sample - loss: 3.0009 - avg_acc: 0.8325 - val_loss: 2.3018 - val_avg_acc: 0.8675
Epoch 132/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.9940 - avg_acc: 0.8330 - val_loss: 2.2988 - val_avg_acc: 0.8674
Epoch 133/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.9895 - avg_acc: 0.8331 - val_loss: 2.2934 - val_avg_acc: 0.8678
Epoch 134/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.9870 - avg_acc: 0.8332 - val_loss: 2.2882 - val_avg_acc: 0.8682
Epoch 135/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.9716 - avg_acc: 0.8340 - val_loss: 2.2816 - val_avg_acc: 0.8688
Epoch 136/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.9711 - avg_acc: 0.8340 - val_loss: 2.2790 - val_avg_acc: 0.8686
Epoch 137/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.9658 - avg_acc: 0.8343 - val_loss: 2.2738 - val_avg_acc: 0.8690
Epoch 138/250
378048/378048 [==============================] - 45s 120us/sample - loss: 2.9604 - avg_acc: 0.8347 - val_loss: 2.2679 - val_avg_acc: 0.8695
Epoch 139/250
378048/378048 [==============================] - 45s 119us/sample - loss: 2.9518 - avg_acc: 0.8356 - val_loss: 2.2653 - val_avg_acc: 0.8693
Epoch 140/250
378048/378048 [==============================] - 45s 119us/sample - loss: 2.9444 - avg_acc: 0.8353 - val_loss: 2.2578 - val_avg_acc: 0.8702
Epoch 141/250
378048/378048 [==============================] - 45s 119us/sample - loss: 2.9415 - avg_acc: 0.8353 - val_loss: 2.2537 - val_avg_acc: 0.8703
Epoch 142/250
378048/378048 [==============================] - 45s 119us/sample - loss: 2.9374 - avg_acc: 0.8359 - val_loss: 2.2515 - val_avg_acc: 0.8703
Epoch 143/250
378048/378048 [==============================] - 45s 119us/sample - loss: 2.9294 - avg_acc: 0.8360 - val_loss: 2.2474 - val_avg_acc: 0.8704
Epoch 144/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.9264 - avg_acc: 0.8363 - val_loss: 2.2431 - val_avg_acc: 0.8707
Epoch 145/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.9209 - avg_acc: 0.8364 - val_loss: 2.2396 - val_avg_acc: 0.8709
Epoch 146/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.9130 - avg_acc: 0.8369 - val_loss: 2.2355 - val_avg_acc: 0.8711
Epoch 147/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.9076 - avg_acc: 0.8373 - val_loss: 2.2312 - val_avg_acc: 0.8714
Epoch 148/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.9084 - avg_acc: 0.8370 - val_loss: 2.2285 - val_avg_acc: 0.8716
Epoch 149/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.9021 - avg_acc: 0.8372 - val_loss: 2.2241 - val_avg_acc: 0.8718
Epoch 150/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.8956 - avg_acc: 0.8374 - val_loss: 2.2174 - val_avg_acc: 0.8723
Epoch 151/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8904 - avg_acc: 0.8379 - val_loss: 2.2151 - val_avg_acc: 0.8725
Epoch 152/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8844 - avg_acc: 0.8384 - val_loss: 2.2092 - val_avg_acc: 0.8728
Epoch 153/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.8810 - avg_acc: 0.8383 - val_loss: 2.2084 - val_avg_acc: 0.8727
Epoch 154/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8748 - avg_acc: 0.8387 - val_loss: 2.2050 - val_avg_acc: 0.8729
Epoch 155/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8704 - avg_acc: 0.8389 - val_loss: 2.1967 - val_avg_acc: 0.8736
Epoch 156/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8663 - avg_acc: 0.8389 - val_loss: 2.1967 - val_avg_acc: 0.8734
Epoch 157/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8625 - avg_acc: 0.8392 - val_loss: 2.1916 - val_avg_acc: 0.8738
Epoch 158/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.8562 - avg_acc: 0.8396 - val_loss: 2.1888 - val_avg_acc: 0.8739
Epoch 159/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8518 - avg_acc: 0.8399 - val_loss: 2.1827 - val_avg_acc: 0.8744
Epoch 160/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8473 - avg_acc: 0.8403 - val_loss: 2.1794 - val_avg_acc: 0.8746
Epoch 161/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8448 - avg_acc: 0.8402 - val_loss: 2.1767 - val_avg_acc: 0.8746
Epoch 162/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8382 - avg_acc: 0.8402 - val_loss: 2.1737 - val_avg_acc: 0.8747
Epoch 163/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8352 - avg_acc: 0.8407 - val_loss: 2.1690 - val_avg_acc: 0.8749
Epoch 164/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8303 - avg_acc: 0.8409 - val_loss: 2.1681 - val_avg_acc: 0.8750
Epoch 165/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.8266 - avg_acc: 0.8410 - val_loss: 2.1616 - val_avg_acc: 0.8755
Epoch 166/250
378048/378048 [==============================] - 47s 124us/sample - loss: 2.8220 - avg_acc: 0.8413 - val_loss: 2.1596 - val_avg_acc: 0.8756
Epoch 167/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.8150 - avg_acc: 0.8417 - val_loss: 2.1545 - val_avg_acc: 0.8758
Epoch 168/250
378048/378048 [==============================] - 47s 125us/sample - loss: 2.8116 - avg_acc: 0.8418 - val_loss: 2.1523 - val_avg_acc: 0.8759
Epoch 169/250
378048/378048 [==============================] - 46s 120us/sample - loss: 2.8090 - avg_acc: 0.8419 - val_loss: 2.1487 - val_avg_acc: 0.8761
Epoch 170/250
378048/378048 [==============================] - 45s 120us/sample - loss: 2.8017 - avg_acc: 0.8422 - val_loss: 2.1446 - val_avg_acc: 0.8763
Epoch 171/250
378048/378048 [==============================] - 45s 120us/sample - loss: 2.7995 - avg_acc: 0.8425 - val_loss: 2.1428 - val_avg_acc: 0.8764
Epoch 172/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.7958 - avg_acc: 0.8428 - val_loss: 2.1383 - val_avg_acc: 0.8766
Epoch 173/250
378048/378048 [==============================] - 47s 124us/sample - loss: 2.7922 - avg_acc: 0.8427 - val_loss: 2.1351 - val_avg_acc: 0.8769
Epoch 174/250
378048/378048 [==============================] - 47s 124us/sample - loss: 2.7881 - avg_acc: 0.8432 - val_loss: 2.1309 - val_avg_acc: 0.8773
Epoch 175/250
378048/378048 [==============================] - 47s 124us/sample - loss: 2.7827 - avg_acc: 0.8433 - val_loss: 2.1282 - val_avg_acc: 0.8772
Epoch 176/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7775 - avg_acc: 0.8436 - val_loss: 2.1265 - val_avg_acc: 0.8772
Epoch 177/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7738 - avg_acc: 0.8437 - val_loss: 2.1227 - val_avg_acc: 0.8776
Epoch 178/250
378048/378048 [==============================] - 45s 120us/sample - loss: 2.7707 - avg_acc: 0.8441 - val_loss: 2.1201 - val_avg_acc: 0.8778
Epoch 179/250
378048/378048 [==============================] - 45s 120us/sample - loss: 2.7679 - avg_acc: 0.8441 - val_loss: 2.1183 - val_avg_acc: 0.8777
Epoch 180/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7657 - avg_acc: 0.8441 - val_loss: 2.1132 - val_avg_acc: 0.8780
Epoch 181/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7588 - avg_acc: 0.8446 - val_loss: 2.1100 - val_avg_acc: 0.8782
Epoch 182/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7592 - avg_acc: 0.8446 - val_loss: 2.1087 - val_avg_acc: 0.8784
Epoch 183/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7558 - avg_acc: 0.8446 - val_loss: 2.1056 - val_avg_acc: 0.8784
Epoch 184/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7515 - avg_acc: 0.8449 - val_loss: 2.1016 - val_avg_acc: 0.8788
Epoch 185/250
378048/378048 [==============================] - 47s 124us/sample - loss: 2.7451 - avg_acc: 0.8454 - val_loss: 2.0980 - val_avg_acc: 0.8790
Epoch 186/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.7421 - avg_acc: 0.8454 - val_loss: 2.0929 - val_avg_acc: 0.8794
Epoch 187/250
378048/378048 [==============================] - 45s 120us/sample - loss: 2.7385 - avg_acc: 0.8457 - val_loss: 2.0932 - val_avg_acc: 0.8792
Epoch 188/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7368 - avg_acc: 0.8456 - val_loss: 2.0902 - val_avg_acc: 0.8794
Epoch 189/250
378048/378048 [==============================] - 45s 119us/sample - loss: 2.7316 - avg_acc: 0.8458 - val_loss: 2.0867 - val_avg_acc: 0.8797
Epoch 190/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7277 - avg_acc: 0.8462 - val_loss: 2.0821 - val_avg_acc: 0.8800
Epoch 191/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.7220 - avg_acc: 0.8464 - val_loss: 2.0792 - val_avg_acc: 0.8802
Epoch 192/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.7208 - avg_acc: 0.8463 - val_loss: 2.0779 - val_avg_acc: 0.8801
Epoch 193/250
378048/378048 [==============================] - 46s 121us/sample - loss: 2.7184 - avg_acc: 0.8468 - val_loss: 2.0775 - val_avg_acc: 0.8801
Epoch 194/250
378048/378048 [==============================] - 46s 122us/sample - loss: 2.7102 - avg_acc: 0.8473 - val_loss: 2.0718 - val_avg_acc: 0.8805
Epoch 195/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.7080 - avg_acc: 0.8470 - val_loss: 2.0680 - val_avg_acc: 0.8808
Epoch 196/250
378048/378048 [==============================] - 49s 131us/sample - loss: 2.7069 - avg_acc: 0.8472 - val_loss: 2.0668 - val_avg_acc: 0.8807
Epoch 197/250
378048/378048 [==============================] - 51s 136us/sample - loss: 2.7041 - avg_acc: 0.8476 - val_loss: 2.0621 - val_avg_acc: 0.8813
Epoch 198/250
378048/378048 [==============================] - 50s 133us/sample - loss: 2.6988 - avg_acc: 0.8474 - val_loss: 2.0615 - val_avg_acc: 0.8812
Epoch 199/250
378048/378048 [==============================] - 51s 135us/sample - loss: 2.6977 - avg_acc: 0.8476 - val_loss: 2.0591 - val_avg_acc: 0.8812
Epoch 200/250
378048/378048 [==============================] - 50s 133us/sample - loss: 2.6935 - avg_acc: 0.8479 - val_loss: 2.0543 - val_avg_acc: 0.8817
Epoch 201/250
378048/378048 [==============================] - 50s 133us/sample - loss: 2.6925 - avg_acc: 0.8481 - val_loss: 2.0534 - val_avg_acc: 0.8816
Epoch 202/250
378048/378048 [==============================] - 49s 130us/sample - loss: 2.6872 - avg_acc: 0.8480 - val_loss: 2.0506 - val_avg_acc: 0.8818
Epoch 203/250
378048/378048 [==============================] - 49s 131us/sample - loss: 2.6851 - avg_acc: 0.8483 - val_loss: 2.0463 - val_avg_acc: 0.8821
Epoch 204/250
378048/378048 [==============================] - 48s 127us/sample - loss: 2.6812 - avg_acc: 0.8486 - val_loss: 2.0439 - val_avg_acc: 0.8823
Epoch 205/250
378048/378048 [==============================] - 49s 129us/sample - loss: 2.6769 - avg_acc: 0.8487 - val_loss: 2.0453 - val_avg_acc: 0.8820
Epoch 206/250
378048/378048 [==============================] - 51s 136us/sample - loss: 2.6735 - avg_acc: 0.8487 - val_loss: 2.0398 - val_avg_acc: 0.8825
Epoch 207/250
378048/378048 [==============================] - 50s 133us/sample - loss: 2.6738 - avg_acc: 0.8489 - val_loss: 2.0373 - val_avg_acc: 0.8827
Epoch 208/250
378048/378048 [==============================] - 50s 133us/sample - loss: 2.6668 - avg_acc: 0.8494 - val_loss: 2.0366 - val_avg_acc: 0.8826
Epoch 209/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.6650 - avg_acc: 0.8493 - val_loss: 2.0331 - val_avg_acc: 0.8828
Epoch 210/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.6619 - avg_acc: 0.8496 - val_loss: 2.0318 - val_avg_acc: 0.8831
Epoch 211/250
378048/378048 [==============================] - 47s 125us/sample - loss: 2.6607 - avg_acc: 0.8496 - val_loss: 2.0265 - val_avg_acc: 0.8834
Epoch 212/250
378048/378048 [==============================] - 47s 124us/sample - loss: 2.6569 - avg_acc: 0.8497 - val_loss: 2.0250 - val_avg_acc: 0.8833
Epoch 213/250
378048/378048 [==============================] - 47s 125us/sample - loss: 2.6550 - avg_acc: 0.8500 - val_loss: 2.0221 - val_avg_acc: 0.8836
Epoch 214/250
378048/378048 [==============================] - 59s 155us/sample - loss: 2.6501 - avg_acc: 0.8502 - val_loss: 2.0215 - val_avg_acc: 0.8836
Epoch 215/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.6448 - avg_acc: 0.8501 - val_loss: 2.0182 - val_avg_acc: 0.8837
Epoch 216/250
378048/378048 [==============================] - 47s 125us/sample - loss: 2.6458 - avg_acc: 0.8505 - val_loss: 2.0163 - val_avg_acc: 0.8839
Epoch 217/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.6408 - avg_acc: 0.8508 - val_loss: 2.0143 - val_avg_acc: 0.8840
Epoch 218/250
378048/378048 [==============================] - 48s 127us/sample - loss: 2.6368 - avg_acc: 0.8508 - val_loss: 2.0093 - val_avg_acc: 0.8844
Epoch 219/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.6363 - avg_acc: 0.8509 - val_loss: 2.0084 - val_avg_acc: 0.8843
Epoch 220/250
378048/378048 [==============================] - 48s 128us/sample - loss: 2.6301 - avg_acc: 0.8513 - val_loss: 2.0030 - val_avg_acc: 0.8849
Epoch 221/250
378048/378048 [==============================] - 47s 125us/sample - loss: 2.6269 - avg_acc: 0.8514 - val_loss: 2.0023 - val_avg_acc: 0.8849
Epoch 222/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.6272 - avg_acc: 0.8513 - val_loss: 1.9995 - val_avg_acc: 0.8850
Epoch 223/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.6219 - avg_acc: 0.8517 - val_loss: 1.9985 - val_avg_acc: 0.8850
Epoch 224/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.6195 - avg_acc: 0.8516 - val_loss: 1.9955 - val_avg_acc: 0.8852
Epoch 225/250
378048/378048 [==============================] - 49s 130us/sample - loss: 2.6198 - avg_acc: 0.8518 - val_loss: 1.9946 - val_avg_acc: 0.8852
Epoch 226/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.6130 - avg_acc: 0.8518 - val_loss: 1.9914 - val_avg_acc: 0.8854
Epoch 227/250
378048/378048 [==============================] - 48s 128us/sample - loss: 2.6129 - avg_acc: 0.8520 - val_loss: 1.9860 - val_avg_acc: 0.8858
Epoch 228/250
378048/378048 [==============================] - 51s 134us/sample - loss: 2.6111 - avg_acc: 0.8522 - val_loss: 1.9882 - val_avg_acc: 0.8856
Epoch 229/250
378048/378048 [==============================] - 48s 127us/sample - loss: 2.6083 - avg_acc: 0.8524 - val_loss: 1.9858 - val_avg_acc: 0.8857
Epoch 230/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.6035 - avg_acc: 0.8525 - val_loss: 1.9840 - val_avg_acc: 0.8858
Epoch 231/250
378048/378048 [==============================] - 50s 131us/sample - loss: 2.6016 - avg_acc: 0.8529 - val_loss: 1.9833 - val_avg_acc: 0.8858
Epoch 232/250
378048/378048 [==============================] - 50s 132us/sample - loss: 2.5992 - avg_acc: 0.8528 - val_loss: 1.9758 - val_avg_acc: 0.8863
Epoch 233/250
378048/378048 [==============================] - 49s 129us/sample - loss: 2.6004 - avg_acc: 0.8527 - val_loss: 1.9776 - val_avg_acc: 0.8861
Epoch 234/250
378048/378048 [==============================] - 49s 128us/sample - loss: 2.5959 - avg_acc: 0.8530 - val_loss: 1.9751 - val_avg_acc: 0.8863
Epoch 235/250
378048/378048 [==============================] - 51s 135us/sample - loss: 2.5870 - avg_acc: 0.8534 - val_loss: 1.9730 - val_avg_acc: 0.8864
Epoch 236/250
378048/378048 [==============================] - 48s 127us/sample - loss: 2.5874 - avg_acc: 0.8532 - val_loss: 1.9681 - val_avg_acc: 0.8868
Epoch 237/250
378048/378048 [==============================] - 47s 124us/sample - loss: 2.5827 - avg_acc: 0.8536 - val_loss: 1.9668 - val_avg_acc: 0.8869
Epoch 238/250
378048/378048 [==============================] - 49s 128us/sample - loss: 2.5813 - avg_acc: 0.8539 - val_loss: 1.9663 - val_avg_acc: 0.8870
Epoch 239/250
378048/378048 [==============================] - 48s 127us/sample - loss: 2.5789 - avg_acc: 0.8539 - val_loss: 1.9637 - val_avg_acc: 0.8870
Epoch 240/250
378048/378048 [==============================] - 48s 128us/sample - loss: 2.5781 - avg_acc: 0.8539 - val_loss: 1.9643 - val_avg_acc: 0.8870
Epoch 241/250
378048/378048 [==============================] - 47s 125us/sample - loss: 2.5745 - avg_acc: 0.8543 - val_loss: 1.9595 - val_avg_acc: 0.8873
Epoch 242/250
378048/378048 [==============================] - 48s 126us/sample - loss: 2.5707 - avg_acc: 0.8546 - val_loss: 1.9556 - val_avg_acc: 0.8875
Epoch 243/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.5691 - avg_acc: 0.8544 - val_loss: 1.9539 - val_avg_acc: 0.8876
Epoch 244/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.5710 - avg_acc: 0.8545 - val_loss: 1.9537 - val_avg_acc: 0.8876
Epoch 245/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.5649 - avg_acc: 0.8546 - val_loss: 1.9512 - val_avg_acc: 0.8877
Epoch 246/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.5631 - avg_acc: 0.8548 - val_loss: 1.9480 - val_avg_acc: 0.8880
Epoch 247/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.5582 - avg_acc: 0.8551 - val_loss: 1.9436 - val_avg_acc: 0.8882
Epoch 248/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.5560 - avg_acc: 0.8554 - val_loss: 1.9449 - val_avg_acc: 0.8881
Epoch 249/250
378048/378048 [==============================] - 46s 123us/sample - loss: 2.5574 - avg_acc: 0.8551 - val_loss: 1.9401 - val_avg_acc: 0.8883
Epoch 250/250
378048/378048 [==============================] - 47s 123us/sample - loss: 2.5501 - avg_acc: 0.8555 - val_loss: 1.9398 - val_avg_acc: 0.8883




Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[9.7449172e-01 1.2958356e-02 1.8279134e-05 7.8260746e-06 7.7191915e-05
   9.7020611e-04 2.4777253e-03 2.6691562e-04 2.8320891e-03 3.3279441e-04
   5.8293052e-04 5.0952276e-05 8.7441709e-05 4.5255944e-03 2.7869680e-04
   1.9244297e-05 6.8660397e-06 1.2909835e-05 7.7150918e-07 1.0013412e-06
   4.5823711e-07]
  [3.1995663e-01 4.4688856e-04 4.8690978e-05 4.8189479e-05 9.8632299e-05
   2.1665855e-03 6.7564255e-01 2.5772073e-04 3.8116068e-05 1.7048316e-05
   1.4829877e-04 5.2950421e-05 8.6995506e-06 1.0437223e-03 1.5276912e-05
   4.4403982e-06 2.0194959e-06 2.5371858e-06 6.5993959e-07 8.8702450e-08
   2.5940204e-07]
  [9.5488971e-01 3.2542437e-05 7.5058299e-05 2.6513258e-04 3.7716822e-05
   3.0699770e-03 1.4988872e-03 6.4938529e-03 1.0456581e-04 2.9760315e-03
   3.0344272e-02 1.4944017e-04 7.7544773e-06 6.9302309e-06 2.9304305e-05
   9.9486817e-07 1.7123395e-05 6.9864839e-08 2.1980941e-07 2.3800405e-07
   1.3261885e-07]
  [9.9870813e-01 9.2860078e-05 2.7634628e-06 9.2796079e-05 2.2292519e-05
   6.8485817e-05 2.9008638e-04 3.2006175e-04 2.1728288e-04 2.0006958e-06
   3.9666345e-05 4.8865506e-05 8.5456690e-05 1.4586639e-06 7.5013468e-06
   1.6828126e-07 7.1180968e-09 1.1753747e-08 5.8112651e-08 3.2828670e-08
   2.9976142e-08]
  [9.9984169e-01 6.2253152e-05 9.1853838e-07 5.7289822e-07 2.9835551e-06
   5.5652803e-05 1.3237560e-05 5.7651428e-06 6.6092393e-06 1.1863146e-06
   4.8765551e-06 2.5274467e-06 1.0079802e-06 6.2271261e-07 2.2466974e-08
   5.1996492e-09 6.7993426e-08 3.6153538e-09 2.7222971e-08 4.4490145e-09
   6.6075150e-09]
  [9.9946076e-01 2.7734177e-05 2.0886164e-06 8.0735226e-06 1.7342863e-05
   3.4980464e-04 1.1044846e-04 4.7846265e-06 7.6874721e-06 5.9571366e-06
   3.9045840e-06 6.4351866e-07 1.0233342e-07 3.3444485e-07 1.3067984e-08
   1.0543171e-07 8.9119299e-09 2.5135256e-08 8.6803553e-08 3.2163442e-08
   5.7037255e-08]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[9.97819185e-01 1.29824353e-03 2.87031298e-06 3.24222601e-05
   3.84967279e-05 8.27468757e-05 3.65566346e-04 2.43429477e-05
   9.13006370e-05 9.75194562e-05 4.51022788e-05 4.20809411e-05
   1.35203009e-05 2.31489685e-05 1.34186412e-05 5.41403642e-06
   4.85604346e-07 3.66354743e-06 2.39477231e-07 1.36194942e-07
   6.99233880e-08]
  [9.92833734e-01 1.64436211e-03 9.83607515e-06 3.54930598e-05
   7.70865008e-05 1.68857689e-04 4.26519569e-03 3.90560344e-05
   4.78750517e-05 1.02014910e-05 3.10650910e-04 4.32210538e-04
   2.50996054e-05 7.56459922e-05 1.39446893e-05 4.70394343e-06
   4.15038812e-06 1.13224144e-06 6.80200969e-07 5.08684437e-08
   1.04409921e-07]
  [9.96101975e-01 3.04883637e-04 2.82138953e-05 8.00179623e-05
   9.87158492e-05 1.29130378e-03 1.40122851e-04 1.32242989e-04
   2.45194824e-05 1.14034294e-04 1.49302685e-03 8.74578109e-05
   4.12029985e-05 1.25845181e-05 3.12789380e-05 7.33183651e-06
   9.43075429e-06 3.11280331e-07 3.49077226e-07 6.52849053e-07
   2.98010320e-07]
  [9.95538175e-01 1.61440286e-03 7.84304575e-06 1.46087958e-04
   1.13782306e-04 2.88492709e-04 1.09626597e-03 1.11343448e-04
   3.82082857e-04 2.47125554e-05 5.55656909e-04 8.82932000e-05
   2.27030068e-05 6.50665424e-06 2.29389548e-06 6.12085614e-07
   1.58088696e-07 7.24726306e-08 2.35116531e-07 2.68013622e-07
   5.76917891e-08]
  [9.98812318e-01 5.52212528e-04 1.69649065e-05 1.52957567e-04
   8.02139130e-06 3.31821757e-05 1.09714892e-04 3.40435463e-06
   8.32073638e-05 1.07566244e-04 7.42497650e-05 3.89489978e-05
   3.91666526e-06 2.86769750e-06 3.89113630e-08 5.58207276e-08
   5.04456068e-08 3.11371373e-08 8.80922926e-08 6.77435850e-08
   8.14234298e-08]
  [9.98187721e-01 1.07899413e-03 1.69858558e-05 8.56915631e-06
   2.45148985e-04 8.60706496e-05 2.28966863e-04 1.57740233e-05
   9.91378838e-05 1.47092051e-05 5.98297675e-06 9.53098242e-06
   2.87616473e-07 6.07051902e-07 5.73626764e-08 3.91627566e-07
   1.02345098e-07 1.90845469e-07 4.84311784e-07 1.73573000e-07
   1.17281054e-07]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[9.98726904e-01 1.00276329e-05 4.12047302e-06 1.64441481e-05
   4.67824430e-06 1.38806008e-05 1.79809052e-04 7.59530114e-04
   2.16810149e-05 2.51720849e-05 1.91817817e-04 1.80645839e-05
   7.73290412e-06 5.17985063e-06 1.17087648e-05 1.79958806e-06
   1.38901740e-07 1.16669264e-06 3.81031278e-08 2.36735769e-08
   5.09742009e-08]
  [9.60167825e-01 4.83515669e-06 1.02530657e-05 3.75575610e-02
   2.28070257e-05 3.42536659e-05 9.63147904e-04 6.36696292e-04
   2.49690667e-04 3.19996834e-05 6.32644078e-05 2.48457727e-05
   2.22283081e-04 2.68937652e-06 1.79730193e-06 3.40518068e-06
   1.44218257e-06 6.27281395e-07 1.44715827e-07 3.22079018e-07
   1.15503241e-07]
  [7.35165849e-02 2.36124478e-07 7.49335129e-07 8.28150496e-06
   4.40145413e-06 3.75872219e-06 1.77900238e-05 9.26274121e-01
   1.11356800e-04 1.03176308e-05 1.81805099e-05 1.25161878e-05
   1.96568799e-05 4.39843092e-07 9.43234966e-07 9.58521582e-08
   5.74175829e-07 3.95624795e-08 1.34430085e-08 1.52339119e-08
   6.69691858e-09]
  [9.48640108e-01 9.50352660e-06 1.05257377e-05 3.51556919e-05
   3.18797829e-05 3.45061489e-05 1.58584677e-04 1.02060661e-03
   3.39642313e-04 4.13831556e-04 1.39588128e-05 6.12517761e-05
   4.92117815e-02 1.72705968e-05 9.88700094e-07 1.11103660e-07
   4.47664306e-08 2.03515498e-08 1.35810396e-07 1.29321066e-07
   1.81689401e-08]
  [9.99638438e-01 2.34413055e-05 8.49900289e-07 5.18354796e-07
   5.64311051e-07 1.40405944e-04 7.03839623e-06 6.99131706e-05
   6.01631946e-05 1.05941754e-05 1.58333278e-05 1.57978520e-05
   1.24244498e-05 3.64325615e-06 9.24262551e-08 1.37597018e-08
   1.15686177e-07 2.46477398e-08 4.94420220e-08 5.36973701e-08
   5.12231502e-08]
  [9.99863386e-01 2.50518156e-06 3.49144500e-07 9.58358032e-06
   7.10079007e-07 5.24819961e-06 6.20465798e-05 2.80844506e-05
   4.79666880e-07 1.09868699e-06 2.62527883e-05 2.03467806e-07
   3.74435736e-08 2.41734988e-08 1.71098835e-09 2.73761795e-08
   1.96790473e-09 2.15044027e-09 1.12264855e-08 1.30559803e-08
   6.76106504e-09]]]
Answer: 
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[1.04476742e-01 1.51959050e-03 1.00174911e-05 1.41957507e-05
   8.55505205e-05 3.52894240e-05 3.11682443e-03 3.24249631e-05
   1.06224121e-04 9.95266673e-05 5.03284173e-06 2.58609623e-04
   3.57596407e-04 8.89233649e-01 6.30497001e-04 8.27691292e-06
   2.22358744e-06 3.01494742e-06 2.74531340e-06 9.04084914e-07
   1.07782216e-06]
  [9.88872945e-01 2.99598440e-04 5.18644927e-04 2.46004754e-04
   3.16258403e-03 1.48091902e-04 1.23614469e-03 4.26725164e-05
   5.66044355e-06 1.17774798e-05 5.52678830e-06 2.29657278e-04
   1.13086287e-04 4.89813834e-03 1.17193238e-04 5.98737233e-06
   7.39450770e-05 1.09434586e-05 6.57998498e-07 3.89723340e-07
   3.92915979e-07]
  [9.98292744e-01 2.70629302e-04 6.93589072e-06 8.82530236e-04
   3.11134063e-04 5.81377826e-05 9.35304633e-05 4.95399618e-05
   4.88357500e-06 3.61518141e-06 9.14898294e-07 7.89084254e-07
   9.60188686e-07 5.32759668e-06 1.55712351e-05 2.68997013e-07
   2.30914179e-06 1.24069715e-08 1.30369187e-07 3.74154796e-09
   1.48236179e-08]
  [9.99146342e-01 6.34600729e-05 5.41768941e-07 3.36361205e-04
   1.27655776e-05 4.09205750e-05 3.24912922e-04 9.56219719e-06
   5.13148407e-05 5.20112565e-07 1.86742523e-06 8.40901430e-06
   1.21420692e-06 1.24001963e-06 2.66869364e-07 6.23175964e-08
   1.95503560e-08 2.37433895e-09 6.73221301e-09 3.79730523e-08
   2.55265977e-08]
  [9.99936223e-01 3.63085892e-05 1.00873149e-06 4.05907531e-06
   4.49868458e-06 5.40157544e-07 6.35858100e-07 7.25015809e-07
   1.17577338e-06 6.02374115e-08 3.31444676e-06 7.22889627e-06
   4.44332500e-07 2.74310469e-06 1.39310714e-07 4.37546213e-08
   6.05422201e-07 9.18601373e-09 2.04715800e-08 1.30320501e-08
   1.05080602e-08]
  [9.99878168e-01 2.92762252e-05 3.53810356e-06 2.11732422e-05
   5.99622799e-05 1.16157116e-06 2.91812694e-06 1.82980330e-07
   1.87655110e-06 5.28777832e-07 5.35730500e-08 5.66528627e-07
   6.00591932e-08 1.82086861e-08 3.38074213e-09 2.45317384e-08
   1.91960723e-08 1.22380550e-08 1.53170376e-07 7.86562424e-08
   1.65564856e-07]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[8.67669344e-01 5.18665798e-02 1.22930127e-04 9.04937740e-04
   1.85245667e-02 1.30977598e-03 7.75725814e-03 3.87821323e-03
   1.74491964e-02 2.49842815e-02 1.69918267e-03 1.21373963e-03
   5.99038962e-04 8.86604015e-04 9.19856247e-05 4.60260984e-04
   1.67319246e-04 1.29152453e-04 1.71643100e-04 6.35265460e-05
   5.05114622e-05]
  [4.15741831e-01 1.24801192e-02 1.22977719e-02 2.50616926e-04
   4.10720566e-03 2.60412903e-03 2.31010076e-02 9.34874988e-04
   4.31024609e-03 4.91563052e-01 2.37645190e-02 2.77479202e-03
   7.55497371e-04 2.45652278e-03 2.17613508e-03 2.88684649e-04
   6.83340331e-05 1.25114238e-04 1.16247196e-04 2.14493757e-05
   6.17980331e-05]
  [7.08646417e-01 4.89780717e-02 1.06352055e-03 1.47379190e-03
   3.52697005e-03 3.72162764e-03 3.04329861e-03 6.48360816e-04
   6.31198287e-03 1.22370329e-02 1.99394077e-01 1.50854758e-03
   3.98589618e-04 7.80294929e-03 4.78573551e-04 1.76671194e-04
   2.63190974e-04 6.11022915e-05 1.00627360e-04 9.40737955e-05
   7.06655410e-05]
  [5.91184258e-01 1.39913545e-03 1.08094234e-03 2.79839367e-01
   1.11871178e-03 3.40593397e-03 1.25452150e-02 8.14423256e-04
   4.19593975e-03 3.62725067e-03 9.29257944e-02 5.56720514e-03
   2.11787337e-04 3.09547497e-04 1.15110213e-03 1.52729554e-04
   1.41045937e-04 2.22309754e-05 1.69382998e-04 7.31996988e-05
   6.48049099e-05]
  [2.65184909e-01 4.16832557e-03 1.82775635e-04 1.30759156e-03
   4.97143995e-03 1.01355006e-04 6.50965900e-04 3.90900392e-03
   7.13701308e-01 1.34829502e-03 1.88800972e-03 1.71181001e-03
   2.78097927e-04 2.63784896e-04 6.31971416e-05 1.93475935e-05
   2.36489668e-05 1.81564810e-05 6.50809161e-05 1.90132450e-05
   1.23972350e-04]
  [9.52690542e-01 1.57712977e-02 9.69179673e-04 2.63566559e-04
   1.81738520e-03 1.03673025e-03 8.60439613e-03 2.35903804e-04
   3.56596196e-03 1.34770712e-02 2.47377775e-05 2.86322582e-04
   2.97294871e-04 4.36818256e-04 8.89072835e-05 6.51383307e-05
   1.00820122e-04 1.14066919e-04 5.93448785e-05 7.12762267e-05
   2.33060400e-05]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[9.86691594e-01 1.22851152e-02 5.08321682e-06 1.34807237e-06
   3.22379638e-05 2.05352644e-05 3.61774786e-04 6.81125239e-05
   1.62829718e-04 4.72720649e-06 9.52736518e-05 2.29386816e-04
   2.48948800e-06 2.31661852e-05 1.19606366e-05 2.06979098e-06
   7.78912352e-07 1.50012909e-06 8.75221051e-09 7.66284742e-08
   1.33178117e-08]
  [6.71515107e-01 5.40668443e-05 1.14826162e-05 8.47661140e-05
   6.15590774e-02 9.75916191e-05 2.64348894e-01 1.94151967e-03
   1.00670499e-04 2.15401742e-05 1.78399438e-04 4.66115125e-05
   4.35095899e-06 3.01799882e-05 4.97193923e-07 2.02493680e-07
   3.80988126e-06 2.39051133e-07 1.77606907e-07 1.04924816e-08
   8.30467854e-07]
  [4.52230364e-01 1.31407171e-04 7.05321600e-06 8.37485786e-05
   1.08335218e-04 5.64858667e-04 4.35387628e-04 1.05353193e-02
   3.60543847e-01 2.45213363e-04 1.74058273e-01 1.01583463e-03
   3.04855166e-05 6.89136550e-06 1.15678904e-06 4.12052600e-07
   1.23815357e-06 2.50695589e-08 4.86545844e-08 6.10396143e-08
   1.86229023e-08]
  [9.93161440e-01 2.93280871e-04 7.17489115e-07 3.98389238e-04
   8.65068796e-06 4.66311794e-05 1.22604962e-03 8.77010243e-05
   7.68889266e-04 1.64363937e-05 5.58679109e-04 3.30515933e-04
   9.06376925e-04 2.17923010e-03 1.57740178e-05 1.05133086e-06
   1.19714556e-07 3.26146008e-08 4.16509494e-08 2.83166628e-08
   1.31801050e-08]
  [9.99566615e-01 2.74064387e-05 8.39312122e-07 1.25197596e-06
   1.96102997e-06 2.76290689e-06 8.51884906e-05 1.00638727e-06
   2.87099945e-04 1.58953742e-06 4.62698927e-06 1.73542976e-05
   2.75311038e-07 1.97090480e-06 5.01054265e-09 3.89384303e-09
   1.99597028e-09 1.15386878e-09 5.65942759e-09 1.35913405e-08
   1.80476505e-08]
  [9.99925852e-01 6.55654367e-06 1.09812227e-07 1.79519219e-07
   1.54587087e-05 7.91131470e-07 6.11899941e-06 1.28265401e-05
   1.08938766e-05 8.58183057e-07 9.00890086e-07 1.94639524e-05
   3.57569596e-09 9.55673443e-08 2.00808328e-10 6.60683597e-09
   1.33008338e-09 6.24989227e-10 1.70855796e-09 7.91819443e-10
   1.26376343e-09]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[4.33956385e-01 1.01130689e-04 1.09896886e-04 3.32745927e-04
   7.59259164e-02 8.16987376e-05 1.78932888e-03 4.83423054e-01
   1.17956300e-03 1.01800158e-03 1.73146173e-03 1.96015928e-04
   1.22688134e-05 4.81236639e-05 1.75132136e-05 1.12879861e-05
   8.43211183e-06 1.62492984e-06 4.12499867e-05 6.76390664e-06
   7.56239660e-06]
  [1.38203148e-02 8.68799689e-05 9.83198261e-05 1.44974403e-02
   4.82764735e-04 8.19320558e-04 2.28111327e-04 2.60819169e-03
   4.44037054e-04 9.66477573e-01 1.22644429e-04 5.49188280e-06
   2.13180261e-04 2.38610901e-05 4.84527573e-06 5.42462258e-05
   2.81921984e-06 1.94170775e-06 3.09596476e-06 4.71550038e-06
   2.04483186e-07]
  [1.06820296e-02 6.14467208e-05 5.94330459e-06 2.80219301e-05
   3.46665122e-02 3.20559302e-05 2.77207000e-05 9.50881720e-01
   5.07828663e-04 2.94483989e-03 9.52993651e-06 6.14724740e-06
   2.06883260e-06 1.13274393e-04 5.14194153e-06 1.37196082e-06
   1.70755739e-05 1.06801735e-06 3.44999034e-06 1.53452288e-06
   1.10432904e-06]
  [3.63589972e-02 2.58389027e-05 9.62885737e-04 5.41339209e-03
   4.17911579e-05 3.93502647e-04 7.70935416e-03 3.91194364e-04
   9.77800300e-05 9.47448313e-01 3.41411651e-05 5.27582813e-07
   1.08070031e-03 2.32123257e-05 8.10994879e-06 4.33414442e-07
   9.64846663e-07 3.21172070e-06 2.54573956e-06 2.16607827e-06
   8.73897875e-07]
  [4.40645926e-02 1.19050703e-04 1.62542914e-04 1.37991412e-06
   2.33234132e-05 3.52671952e-04 7.21453252e-05 9.54546154e-01
   4.99481219e-04 6.52362951e-06 8.26724354e-05 4.44223551e-05
   3.42063367e-06 2.36610890e-06 4.87212537e-06 2.95951259e-06
   3.03928005e-06 4.38243114e-06 2.73551495e-06 5.17116575e-07
   8.14507359e-07]
  [9.89279568e-01 1.43850659e-04 2.29231155e-05 3.18812183e-03
   2.94766331e-04 1.40131406e-05 3.61196068e-03 3.25659057e-03
   4.48635365e-06 1.10338107e-04 3.80551392e-05 2.37975974e-06
   1.55418293e-05 2.22588073e-06 4.30543378e-06 1.45957881e-06
   3.41190400e-07 8.56964391e-07 5.20262938e-06 1.64813480e-06
   1.41685155e-06]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[9.96142924e-01 4.44373873e-05 2.21497558e-05 4.38185161e-05
   5.61780362e-05 1.96605077e-04 1.90245755e-05 2.15796381e-03
   1.95814311e-04 3.62035469e-04 6.30274590e-05 1.84748162e-04
   4.82465228e-04 7.25558129e-06 7.76769139e-06 9.22328854e-06
   1.73018736e-06 2.02902288e-06 2.69710739e-07 3.01754170e-07
   2.85378121e-07]
  [7.87163973e-01 5.98348888e-05 6.90222150e-05 6.78740762e-05
   8.03050352e-04 2.06842750e-01 9.73169226e-04 1.09586469e-03
   7.88728823e-04 4.47236438e-04 1.02640607e-03 8.57060877e-05
   2.98967410e-04 2.03108953e-04 4.84128141e-05 3.27988391e-06
   6.14933060e-06 9.01954809e-06 3.02477360e-06 1.50417429e-06
   2.88996921e-06]
  [1.84157699e-01 1.27544254e-05 1.95255616e-05 4.79158189e-05
   2.27647673e-04 1.38546329e-03 1.84741017e-04 6.00028550e-04
   1.13005610e-03 8.11462164e-01 6.43845124e-04 8.20083587e-05
   3.55207449e-05 5.31824571e-06 1.14369789e-06 5.29941872e-07
   2.52468885e-06 2.51780108e-07 2.52876703e-07 3.86209564e-07
   2.47214444e-07]
  [9.75802481e-01 1.05605723e-04 6.50411763e-04 9.14861375e-05
   5.24720061e-04 1.34450721e-03 1.73731521e-03 3.59552563e-03
   9.82018537e-04 8.09495710e-03 2.03648745e-03 2.67523516e-04
   2.79227679e-04 1.90170089e-04 4.28717025e-03 7.22449499e-07
   7.60123669e-07 4.78885204e-06 1.48983622e-06 1.93922688e-06
   6.38647521e-07]
  [9.96639371e-01 2.38204200e-04 2.86440318e-05 4.47288694e-05
   1.18267402e-04 5.25912736e-04 9.82929778e-05 7.11452682e-04
   9.87418825e-05 5.59451990e-04 5.83917950e-04 3.09653085e-04
   2.71437930e-05 1.36385415e-05 4.72040938e-07 1.75863420e-07
   5.33736795e-07 1.20034841e-07 5.27048883e-07 2.43537556e-07
   3.65386768e-07]
  [9.97187555e-01 2.28575736e-05 2.00201248e-05 1.37301504e-05
   3.57565041e-05 1.30166835e-03 9.86485757e-05 2.45969306e-04
   7.86136196e-04 2.41363668e-04 3.06524307e-05 9.82118399e-06
   2.47276375e-07 2.01960779e-06 2.16695113e-07 6.54879500e-07
   6.88793534e-07 1.14479150e-07 9.95447635e-07 4.88340220e-07
   3.89804285e-07]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[9.30389464e-01 1.70649719e-06 3.28352962e-06 6.46320954e-02
   8.10780148e-06 4.63101605e-05 1.67766848e-05 1.74631458e-03
   2.08958541e-03 4.68869170e-04 2.57375475e-04 8.60849468e-05
   1.40515549e-04 1.21782878e-05 9.36774741e-05 3.83005909e-06
   2.01997736e-07 2.87098987e-06 1.85674210e-07 1.45036267e-08
   5.68742564e-07]
  [3.24718922e-01 9.07339745e-06 1.72649379e-06 7.04111953e-05
   8.15804015e-05 4.52631830e-05 1.53356450e-06 3.05424968e-04
   6.73621178e-01 7.92204155e-05 1.77721624e-04 2.62212398e-05
   7.49483239e-04 5.53093996e-05 4.06639119e-05 1.23667160e-05
   2.31559807e-06 1.37107270e-06 9.80317125e-08 5.58899202e-08
   2.96058467e-08]
  [8.39422047e-01 1.45789193e-06 6.65090056e-07 3.07825176e-05
   3.02357330e-05 9.90708286e-05 6.41936131e-05 4.89253085e-04
   2.17882032e-03 2.02544019e-04 9.06668174e-06 3.11010575e-04
   1.57064945e-01 5.29296631e-05 2.31134236e-05 2.70282300e-07
   1.92116167e-05 7.18877047e-08 1.32250221e-07 1.70879318e-07
   4.65969130e-08]
  [9.99161482e-01 2.45858701e-06 1.48528358e-07 6.07260517e-07
   1.29427226e-05 2.33175626e-04 1.35250802e-05 2.64344199e-05
   1.11453664e-04 3.94346025e-05 6.79222721e-05 1.63830802e-04
   1.02765654e-04 5.66427079e-05 7.01744784e-06 3.26397966e-08
   1.29607729e-08 3.37650841e-09 2.46812704e-08 2.71853597e-08
   8.77699424e-09]
  [9.99960423e-01 8.91206753e-07 1.17411822e-07 1.48718505e-06
   1.41893040e-08 2.45044112e-06 1.98850373e-07 1.12857924e-06
   5.93171171e-06 1.51512529e-06 1.75901896e-05 3.82685812e-06
   1.39284668e-06 3.13326586e-06 4.73216089e-09 4.29989777e-09
   1.86397786e-09 1.13412546e-09 7.69755149e-10 2.97961100e-09
   4.86541962e-09]
  [9.99957085e-01 9.97063012e-07 9.25203210e-07 5.55642100e-06
   6.43685053e-06 5.67229426e-06 1.52730331e-06 2.41337693e-06
   8.87474926e-06 6.13531483e-07 1.22333392e-06 8.53494203e-06
   9.85243318e-08 3.48645308e-08 1.34397227e-09 2.29968009e-08
   2.58661959e-09 9.49512380e-09 1.37055105e-08 6.37931041e-09
   8.28252045e-09]]]
Answer: 
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] 
 Prediction: 
 [[[9.99686956e-01 1.16261635e-05 3.81402856e-07 7.77161767e-06
   6.73211480e-06 2.72637426e-05 3.63044528e-05 1.24590195e-04
   2.40562222e-05 3.33294556e-05 2.50562698e-05 9.22611162e-06
   3.44105251e-06 1.06553296e-06 1.65019742e-06 2.56469633e-07
   5.68140877e-08 2.25375800e-07 1.73096772e-08 3.91175448e-09
   6.31177910e-09]
  [9.98892486e-01 1.59677129e-05 9.82238817e-07 1.69833802e-05
   8.56116385e-05 9.33736737e-05 1.56931565e-04 6.54249816e-05
   1.40718432e-04 5.82970024e-05 3.53849755e-04 8.32943115e-05
   2.56560252e-05 6.60142814e-06 2.73481123e-06 5.94686298e-07
   3.49694744e-07 2.20804353e-07 6.19498266e-08 5.88168980e-09
   1.58863180e-08]
  [9.97695625e-01 9.13633176e-06 1.75135233e-06 9.12445466e-06
   5.29411445e-05 1.85520475e-04 1.86401085e-05 3.43215826e-04
   5.02680719e-04 5.31881815e-04 5.05170086e-04 1.00679667e-04
   3.20452964e-05 3.59016417e-06 5.24409779e-06 5.43719409e-07
   2.13156932e-06 3.32725989e-08 2.04279669e-08 7.73870781e-08
   3.02989740e-08]
  [9.98519480e-01 3.28898241e-05 3.34277593e-06 2.59352237e-05
   2.06244440e-05 5.82196808e-05 1.20609249e-04 1.21455312e-04
   1.64116980e-04 2.75145547e-04 5.51847741e-04 4.94230808e-05
   3.32407581e-05 2.08533165e-05 2.70996065e-06 3.62624135e-08
   2.69546714e-08 1.04882698e-08 2.12469420e-08 4.19666435e-08
   4.36033565e-09]
  [9.99467909e-01 2.88588835e-05 3.49000902e-06 6.64385743e-06
   9.42923180e-07 7.38804647e-06 3.74744668e-05 3.85496023e-05
   2.29505298e-04 1.07765860e-04 6.05353380e-05 7.70058796e-06
   2.25177041e-06 1.02044180e-06 5.54153612e-09 4.82981966e-09
   4.66113059e-09 4.87877960e-09 7.14967463e-09 1.68558945e-08
   1.54320041e-08]
  [9.99862671e-01 4.57356764e-05 1.31473701e-06 3.60091440e-06
   9.07661706e-06 1.16665842e-05 2.18685273e-05 1.74341949e-05
   1.78574428e-05 4.40986287e-06 1.35423113e-06 2.94524330e-06
   1.92391738e-08 2.30297008e-08 3.01227221e-09 1.15948025e-08
   5.82282000e-09 6.11070750e-09 1.57051918e-08 6.69981404e-09
   3.91736243e-09]]]